# Movies Assistant

<p align="center">
  <img src="images/banner.jpg">
</p>

Keeping up with movie recommendations can be overwhelming, especially with so many options available. Finding something tailored to your taste isn't always easy, and movie critics or friends aren't always around for advice.

The Movies Assistant offers a conversational AI that helps users discover films based on their preferences, providing personalized suggestions to make movie nights more enjoyable.

This project was implemented for [LLM Zoomcamp](https://github.com/DataTalksClub/llm-zoomcamp) - a free course about LLMs and RAG.

## Project Overview

The Movies Assistant is a RAG (Retrieval-Augmented Generation) application designed to assist users in navigating and exploring the world of movies with ease.

The main use cases include:

1. **Answer Movie-Related Queries**: Responding to specific questions about movies, actors, directors, or production details.
2. **Give Movie Recommendations**: Offering personalized movie suggestions based on user preferences like genre, mood, or popularity.
3. **Summarize Movie Plots**: Providing concise summaries of movie plots to help users decide what to watch.
4. **Generate Movie Reviews**: Creating movie reviews by analyzing information and providing opinions based on various factors.
5. **Compare Movies**: Helping users compare different movies based on aspects such as ratings, genre, or popularity.
6. **Provide Actor/Director Filmography**: Listing movies by a particular actor or director for users looking to explore their works.
7. **Sentiment Analysis of Movie Reviews**: Analyzing and summarizing the general sentiment of reviews for a specific movie.
8. **Conversational Interaction**: Enabling users to find relevant movie information and suggestions effortlessly through natural, conversational queries, without needing to search through various databases or platforms.

## Dataset

The dataset used for this project is the [Movies Daily Update Dataset](https://www.kaggle.com/datasets/akshaypawar7/millions-of-movies), sourced from Kaggle. The raw dataset consists of approximately 720,000 movies, collected from the TMDB dataset.

After a thorough process of cleaning and filtering, the following key attributes were retained to focus on relevant movie information:

- **id**: Unique identifier for each movie
- **title**: Movie title
- **genres**: Genres associated with the movie
- **original_language**: Language in which the movie was originally produced
- **overview**: Brief description of the movie's plot
- **popularity**: Popularity score
- **production_companies**: Studios or companies involved in production
- **release_date**: Date when the movie was released
- **budget**: Estimated production budget
- **revenue**: Total revenue generated by the movie
- **runtime**: Length of the movie in minutes
- **status**: Release status (e.g., Released, Planned, ...)
- **tagline**: Movie's tagline or slogan
- **vote_average**: Average user rating
- **vote_count**: Total number of user ratings
- **credits**: Information about the cast and crew
- **keywords**: Key terms associated with the movie

This curated dataset provides a structured foundation for the project, enabling better recommendations and analysis.

## Technologies

- Python 3.11
- Docker and Docker Compose for containerization
- [Minsearch](https://github.com/alexeygrigorev/minsearch), ElasticSearch for full-text search
<!-- - Flask as the API interface (see [Background](#background) for more information on Flask) -->
<!-- - Grafana for monitoring and PostgreSQL as the backend for it -->
- HuggingFace models as an LLM

## Setup

To get started, youâ€™ll need to provide your Hugging Face API key:

1. Install `direnv`.
2. Copy the `.envrc_template` file to a new `.envrc` file and add your API key inside.
3. Run `direnv allow` to load the API key into your environment.

For managing dependencies, we use `pipenv`. To install it, run:

```bash
pip install pipenv
```

Once `pipenv` is installed, you can install the app dependencies by running:

```bash
pipenv install --dev
```
## TODO
- **Search engine**: too much time for elasticSeach indexing large data, find faster way
- **Evaluating retrieval**: too large dataset, must generating about 4 milions question in ground truth data, find new better way to evaluating 
- **RAG evaluation**: as above
- **Interface**: Flask
- **Ingestion pipeline**
- **Monitoring**: Grafana
- **Containerization**

## Code
TODO
## Running the application
TODO
## Using the application
TODO
## Experiments
TODO
## Monitoring
TODO
